name: ğŸ•· Run TIAA ETL Crawler and Upload to Supabase

on:
  schedule:
    - cron: "30 1 * * *"  # Runs daily at 7:00 AM IST (1:30 AM UTC)
  workflow_dispatch:  # Allows manual trigger

jobs:
  run-etl:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: true  # Keeps GITHUB_TOKEN for git push

      - name: ğŸ Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt supabase

      - name: ğŸ•· Run Scrapy spider
        run: |
          mkdir -p output
          python -m scrapy crawl bankrate_spider -s LOG_LEVEL=WARNING

      - name: ğŸ§¾ Append .jsonl data to CSV
        run: python append_json_csv.py

      - name: ğŸš€ Upload data to Supabase
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          SUPABASE_TABLE: mortgage_rates
        run: |
          echo "SUPABASE_URL is set (masked for security)."
          python upload_to_supabase.py

      - name: ğŸ“ Upload CSV as artifact (optional)
        uses: actions/upload-artifact@v4
        with:
          name: mortgage_rates_csv
          path: output/mortgage_rates.csv

      - name: ğŸ“ Configure Git user
        run: |
          git config --global user.email "actions@github.com"
          git config --global user.name "GitHub Actions"

      - name: ğŸ’¾ Add, commit and push updated CSV
        run: |
          git add -f output/mortgage_rates.csv
          git diff --cached --quiet || git commit -m "Update mortgage_rates.csv after ETL run"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
