name: ğŸ•· Run TIAA ETL Crawler

on:
  schedule:
    - cron: "30 1 * * *"  # 7:00 AM IST = 1:30 AM UTC
  workflow_dispatch:  # allows manual runs too

jobs:
  run-etl:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: ğŸ•· Run Scrapy spider
        run: |
          mkdir -p output
          python -m scrapy crawl bankrate_spider -s LOG_LEVEL=WARNING

      - name: ğŸ§¾ Append .jsonl to CSV
        run: python append_json_csv.py

      - name: ğŸš€ Upload data to Supabase
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          SUPABASE_TABLE: mortgage_rates
        print(f"SUPABASE_URL: '{SUPABASE_URL}'")

      - name: ğŸ“ Upload CSV as artifact (optional)
        uses: actions/upload-artifact@v4
        with:
          name: mortgage_rates_csv
          path: output/mortgage_rates.csv

      - name: ğŸ“ Configure Git
        run: |
          git config --global user.email "actions@github.com"
          git config --global user.name "GitHub Actions"

      - name: ğŸ’¾ Add, commit and push mortgage_rates.csv
        run: |
          git add -f output/mortgage_rates.csv
          git diff --cached --quiet || git commit -m "Update mortgage_rates.csv after ETL run"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
